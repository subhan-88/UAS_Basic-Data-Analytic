# Project: ML Classification - Credit Scoring Analysis

# Directory Structure:
# 1. data/credit_scoring_dataset.csv (Dataset)
# 2. notebooks/eda_visualizations.ipynb (Jupyter Notebook for EDA)
# 3. src/preprocessing.py (Data Preprocessing)
# 4. src/modeling.py (Model Training and Evaluation)
# 5. requirements.txt (Required Libraries)

# Main Python Scripts for the Project:

# ------------------- src/preprocessing.py -------------------

import pandas as pd
import numpy as np

def load_and_preprocess_data(file_path):
    """Load and preprocess the dataset."""
    # Load dataset
    data = pd.read_csv(file_path)

    # Rename columns for clarity
    data.rename(columns={"Loan Status": "Approval Status"}, inplace=True)

    # Fill missing values
    for col in ["Age", "Income", "Credit Score", "Employment Length", "Loan Amount"]:
        data[col].fillna(data[col].median(), inplace=True)

    data["Approval Status"].fillna(data["Approval Status"].mode()[0], inplace=True)

    # Convert Approval Status to binary
    data["Approval Status"] = data["Approval Status"].map({"Approved": 1, "Rejected": 0})

    return data

# Example Usage
if __name__ == "__main__":
    data = load_and_preprocess_data("../data/credit_scoring_dataset.csv")
    data.to_csv("../data/processed_data.csv", index=False)
    print("Data preprocessing complete and saved.")

# ------------------- src/modeling.py -------------------

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
import pandas as pd

def train_and_evaluate_models(data_path):
    """Train and evaluate multiple ML models."""
    # Load preprocessed data
    data = pd.read_csv(data_path)

    # Split data into features and target
    X = data.drop("Approval Status", axis=1)
    y = data["Approval Status"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize models
    models = {
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, random_state=42),
        "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
        "KNN": KNeighborsClassifier(n_neighbors=5)
    }

    # Evaluate models
    results = []
    for model_name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        metrics = {
            "Model": model_name,
            "Accuracy": accuracy_score(y_test, y_pred),
            "F1 Score": f1_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred),
            "Recall": recall_score(y_test, y_pred),
            "AUC": roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
        }
        results.append(metrics)

    results_df = pd.DataFrame(results)
    print(results_df)
    results_df.to_csv("../data/model_results.csv", index=False)
    print("Model evaluation complete and results saved.")

# Example Usage
if __name__ == "__main__":
    train_and_evaluate_models("../data/processed_data.csv")

# ------------------- notebooks/eda_visualizations.ipynb -------------------

# Use Jupyter Notebook for EDA (referenced in the structure) to create visualizations.
# Save notebook as eda_visualizations.ipynb for better documentation and presentation.

# ------------------- requirements.txt -------------------
# pandas
# numpy
# matplotlib
# seaborn
# scikit-learn

# End of code
