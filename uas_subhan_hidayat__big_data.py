# -*- coding: utf-8 -*-
"""UAS Subhan Hidayat_ Big Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z6BJ7w-PCq5gmFlfu7wBFqNsIpqucXjV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve

# ğŸ“‚ Load Dataset
df = pd.read_csv("/content/sample_data/spotify_tracks.csv")

# ğŸ“Š Cek Info Dataset
print(df.info())
print(df.head())

# ğŸ” Cek Missing Values & Duplikasi
print("Missing values per column:\n", df.isnull().sum())
print("Duplicate Rows:", df.duplicated().sum())

# ğŸš€ Hapus duplikasi
df = df.drop_duplicates()

# ğŸ“Š Cek Distribusi Popularitas
plt.figure(figsize=(10,5))
sns.histplot(df['popularity'], bins=30, kde=True, color="blue")
threshold = np.percentile(df['popularity'], 75)  # Ambil kuartil ke-75 sebagai batas lagu populer
plt.axvline(threshold, color='red', linestyle='dashed', linewidth=2, label=f'Threshold = {threshold}')
plt.title('Distribusi Popularitas Lagu')
plt.xlabel('Popularitas')
plt.ylabel('Jumlah Lagu')
plt.legend()
plt.show()

# ğŸ”¥ Buat Label Klasifikasi (0 = Tidak Populer, 1 = Populer)
df['popularity_class'] = df['popularity'].apply(lambda x: 1 if x >= threshold else 0)

# ğŸ° Pie Chart Distribusi Kelas
plt.figure(figsize=(6, 6))
df['popularity_class'].value_counts().plot.pie(autopct='%1.1f%%', colors=["lightcoral", "lightblue"], labels=["Tidak Populer", "Populer"])
plt.title("Distribusi Lagu Berdasarkan Popularitas")
plt.ylabel("")
plt.show()

# ğŸ“Œ Korelasi Antar Fitur
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=False, cmap="coolwarm", linewidths=0.5)
plt.title("Matriks Korelasi Antar Fitur")
plt.show()

# ğŸ¯ Pilih Fitur yang Relevan
selected_features = [
    "acousticness", "danceability", "duration_ms", "energy",
    "instrumentalness", "liveness", "loudness", "mode",
    "speechiness", "tempo", "time_signature", "valence"
]

X = df[selected_features]  # Fitur
y = df["popularity_class"]  # Target

# ğŸ† Split Data (80% Train - 20% Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# ğŸš€ Training Model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# ğŸš€ Training Model Gradient Boosting
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# ğŸ¯ Evaluasi Model
def evaluate_model(name, y_true, y_pred):
    print(f"\nğŸ“Œ Model: {name}")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))
    print("AUC-ROC Score:", roc_auc_score(y_true, y_pred))

evaluate_model("Random Forest", y_test, rf_preds)
evaluate_model("Gradient Boosting", y_test, gb_preds)

# ğŸ”¥ Plot ROC Curve
rf_probs = rf_model.predict_proba(X_test)[:, 1]
gb_probs = gb_model.predict_proba(X_test)[:, 1]
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)
gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_probs)

plt.figure(figsize=(8,6))
plt.plot(rf_fpr, rf_tpr, label="Random Forest", color='blue')
plt.plot(gb_fpr, gb_tpr, label="Gradient Boosting", color='red')
plt.plot([0,1], [0,1], linestyle="dashed", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# ğŸ”¥ Tentukan parameter yang ingin diuji
param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [10, 20, 30],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}

# ğŸš€ Inisialisasi model
rf = RandomForestClassifier(random_state=42)

# ğŸ” Grid Search (Cari kombinasi terbaik)
grid_search = GridSearchCV(rf, param_grid, cv=3, scoring="roc_auc", n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# ğŸ“Œ Tampilkan hasil terbaik
print("\nâœ… Best Parameters:", grid_search.best_params_)
best_rf = grid_search.best_estimator_

# ğŸš€ Evaluasi Model Terbaik
best_rf_preds = best_rf.predict(X_test)
print("\nğŸ“Š Evaluasi Model Setelah Tuning:")
evaluate_model("Tuned Random Forest", y_test, best_rf_preds)

